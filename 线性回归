# 线性回归的任务：是构造一个预测函数来映射输入的特征矩阵和标签值的线性关系（预测函数的本质就是需要构建的模型，而构造预测函数的核心就是找出模型的参数向量）
# 多元线性回归：一个样本有多个特征的线性回归问题

# 线性回归的库： linear_model.LinearRegression
# 相关参数：
# 1.fit_intercept:是否计算此模型的截距，布尔值，默认为True，不用改
# 2.normalize:如果为True，则特征矩阵X在进入回归之前将会被减去均值（中心化）并除以L2范式（缩放）。如果希望进行标准化，请在ﬁt数据之前使用preprocessing模块中的标准化专用类StandardScaler，布尔值，默认False，可以不改
# 3.copy_X:标准化时是否保留原值，如果为真，将在X.copy()上进行操作，否则原本的特征矩阵X可能被线性回归影响并覆盖，布尔值，默认True，一般不改
# 4.n_jobs:用于计算的作业数，数据量很大很大的时候设为-1，表示使用全部的CPU来进行计算，填整数或者None，默认None表示1
# 可以看出以上四个参数都不是必填的和无可替代的，说明线性回归的性能往往取决于数据本身而并非调参能力（PS:sklearn中的线性回归可以处理多标签问题，只需要在ﬁt的时候输入多维度标签）

from sklearn.linear_model import LinearRegression as LR
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.datasets import fetch_california_housing as fch #加利福尼亚房屋价值数据集
import pandas as pd

housevalue = fch()
data = pd.DataFrame(housevalue.data)
labels = housevalue.target
# print(data.shape)   #结果：(20640, 8)
# print(labels.shape)    #结果：(20640,)
data.columns = housevalue.feature_names   #把每一列的名称换成特征名称

Xtrain,Xtest,Ytrain,Ytest = train_test_split(data,labels,test_size=0.3,random_state=420)
# print(Xtrain)    #由于分测试集和训练集的时候是随机的，所以现在Xtrain的索引是乱的
for i in [Xtrain,Xtest]:
    i.index = range(i.shape[0])

# 建模
reg = LR().fit(data,labels)   #实例化并训练模型
yhat = reg.predict(Xtest)    #.predict返回测试集的回归结果
# print(yhat)
# print(reg.coef_)   #返回系数，8个，分别是八个特征对应的系数
# print([*zip(Xtrain.columns,reg.coef_)])
# print(reg.intercept_)    #返回截距

##########################模型评估指标#######################
# 看待回归效果的两个角度：1）是否预测到了正确的数值；2）是否拟合到了足够的信息
# ###是否预测到了正确的数值
# sklearn中使用RSS的变体MSE（均方误差）来衡量预测值和真实值之间的差异
# 调用MSE的方法：1）使用sklearn专用的模型评估模块metrics里的类mean_squared_error；2）调用交叉验证的类cross_val_score并使用里面的scoring参数来设置使用均方误差。

from sklearn.metrics import mean_squared_error as MSE
# print(MSE(yhat,Ytest))   #把预测值和真实值输入进行评估     结果：0.5294721708306555
# 通过交叉验证
# print(cross_val_score(reg,data,labels,cv=10,scoring="neg_mean_squared_error"))
# 会发现结果都是负值，这是因为均方误差本身是一种误差，所以被划分为模型的一种损失，在sklearn当中所有的损失都使用负数表示，因此均方误差也被显示为负数了。真正的均方误差MSE的数值，其实就是去掉负号的数字
# 绝对均值误差（MAE）：表达概念与均方误差一致，可使用from sklearn.metrics import mean_absolute_error或者交叉验证中的的scoring = "neg_mean_absolute_error"来调用


# ###是否拟合了足够的信息（数据预测和数据规律）
# R²和EVS（可解释性方差分数）：都是衡量 1 - 我们的模型没有捕获到的信息量占真实标签中所带的信息量的比例，所以两者都是越接近1越好
# R²的三种调用方式：1）直接从metrics中导入r2_score，输入预测值和真实值后打分；2）从线性回归LinearRegression的接口score来进行调用；3）在交叉验证中，输入"r2"来调用
# EVS的两种调用方法：1）从metrics中导入；2）在交叉验证中输入”explained_variance“来调用

from sklearn.metrics import r2_score
r2_1 = r2_score(y_pred=yhat,y_true=Ytest)    #此处要指明那个是预测值，那个是真实值，否则结果可能是错的
# print(r2_1)
r2_2 = reg.score(Xtest,Ytest)
# print(r2_2)  #结果：0.6054317911695412
r2_3 = cross_val_score(reg,data,labels,scoring="r2").mean()
# print(r2_3)    #结果：0.553031114027957

# 调用EVS
from sklearn.metrics import explained_variance_score as EVS
evs1 = EVS(Ytest,yhat)
evs2 = cross_val_score(reg,data,labels,cv=10,scoring="explained_variance").mean()
# print(evs1)
# print(evs2)
# 可以看到，数据结果MSE很小，但R²却不高，说明模型比较好地拟合了数据的数值，却没有能正确拟合数据的分布

# 画图验证
import matplotlib.pyplot as plt
plt.plot(range(len(Ytest)),sorted(Ytest),c="black",label="data")
plt.plot(range(len(yhat)),sorted(yhat),c="r",label="predict")
plt.legend()
plt.show()
